{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deep_arcane.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70xDz2-Q8wRM"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h52FvysZO-L2"
      },
      "source": [
        "RESUME_ID = \"1s3dxn44\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7G6hjHi8XmC"
      },
      "source": [
        "# Mount Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# Silly. We have to mount the drive as that's what the\n",
        "# PyTorch API expects.  However, you can't delete the\n",
        "# trash with a mounted drive. So, we use PyDrive, which\n",
        "# requires a separate token. :facepalm\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "pdrive = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IMXeFWG5ayz"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq1kxYbLv-Ex"
      },
      "source": [
        "# Install Weights and Biases for experiment tracking.  \n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufQBSHTXG82G"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inlinea\n",
        "\n",
        "import os\n",
        "\n",
        "# Usual Suspects.\n",
        "import numpy as np\n",
        "import random\n",
        "from time import sleep\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Image Visualization.\n",
        "from PIL import Image\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# Ignite\n",
        "from ignite.engine import Engine, Events\n",
        "import ignite.distributed as idist\n",
        "\n",
        "# Experiment tracking.\n",
        "import wandb\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 42\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_-njGCCHF_a"
      },
      "source": [
        "# Setup data directory.\n",
        "!mkdir -p \"/content/data/clean_bold_magic_symbols/\"\n",
        "!mkdir \"/content/output/\"\n",
        "\n",
        "# You will need to upload your data file manually Google Drive.\n",
        "!tar -xf  '/content/gdrive/MyDrive/datasets/clean_bold_magic_symbols.tar.gz' -C '/content/data/clean_bold_magic_symbols/'\n",
        "\n",
        "# Uncomment to include icons for extra training data.\n",
        "!mkdir -p \"/content/data/icons/\"\n",
        "!tar -xf  '/content/gdrive/MyDrive/datasets/icons_light.tar.gz' -C '/content/data/icons/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COUNT_OF_TRAINING_IMGS = len([file for _, _, file in os.walk(\"/content/data\")][1])"
      ],
      "metadata": {
        "id": "dVLEx4KImutI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VExeTVdtAf-E"
      },
      "source": [
        "!pip install gputil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKpf9VMfAicz"
      },
      "source": [
        "import GPUtil\n",
        "\n",
        "gpu = GPUtil.getGPUs()\n",
        "gpu_name = gpu[0].name\n",
        "gpu_memory = gpu[0].memoryTotal\n",
        "\n",
        "print(f\"GPU: {gpu_name}\")\n",
        "print(f\"GPU Memory: {gpu_memory}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqFMQRPULWV4"
      },
      "source": [
        "## Batch Size vs. Learning Rate\n",
        "\n",
        "| batch_size |      lr  |\n",
        "|------------|----------|\n",
        "| 4          |  0.002   |\n",
        "| 16         |  0.0001  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ozBIennHMOi"
      },
      "source": [
        "\n",
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oITYUcGHC_2"
      },
      "source": [
        "# Root directory for dataset\n",
        "dataroot = f\"{os.getcwd()}/data/\"\n",
        "output_folder = f\"{os.getcwd()}/output/\"\n",
        "\n",
        "# Where to save models.\n",
        "g_drive_models_dir = \"dl_models/deep_arcane/\"\n",
        "\n",
        "# Model to load.\n",
        "MODEL_DIR = \"/content/gdrive/MyDrive/dl_models/deep_arcane_models/\"\n",
        "\n",
        "# Number of WORKERS for dataloader\n",
        "WORKERS = 2\n",
        "\n",
        "# Number of training epochs\n",
        "EPOCHS = 5000\n",
        "starting_epoch = 0\n",
        "\n",
        "# Epoch to begin checking if we reached a new low loss.\n",
        "EPOCH_TO_START_SAVING = 0\n",
        "\n",
        "# Epoch to evaluate on.\n",
        "EPOCH_TO_EVAL = 3\n",
        "\n",
        "# How many epochs run before saving model\n",
        "save_every = 10\n",
        "\n",
        "# Batch size during training\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "# Learning rate for optimizers\n",
        "# GLR = 0.00001\n",
        "# DLR = 0.00001\n",
        "GLR = 0.0001\n",
        "DLR = 0.0003\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "IMAGE_SIZE = 128\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "NC = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "latent_dim = 18\n",
        "\n",
        "# Size of feature maps in generator\n",
        "NGF = 300\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "NDF = 300\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "G_DROPOUT = 0.0\n",
        "D_DROPOUT = 0.0\n",
        "\n",
        "# Labels\n",
        "real_range = (0.0, 0.0)\n",
        "fake_range = (0.90, 0.95)\n",
        "\n",
        "sample_every = 1\n",
        "samples = 8\n",
        "\n",
        "# Image transformations.\n",
        "convert_to_grayscale = True\n",
        "resize_images = True\n",
        "crop_images = True\n",
        "# random_rotation_degrees = (-30, 30)\n",
        "random_rotation_degrees = (-0, 0)\n",
        "\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "id = wandb.util.generate_id()\n",
        "\n",
        "experiment_settings = {\n",
        "    \"wandb_run_id\": id,\n",
        "    \"dataroot\": dataroot,\n",
        "    \"WORKERS\": WORKERS,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"IMAGE_SIZE\":IMAGE_SIZE,\n",
        "    \"NC\":NC,\n",
        "    \"latent_dim\":latent_dim,\n",
        "    \"NGF\":NGF,\n",
        "    \"NDF\":NDF,\n",
        "    \"EPOCHS\":EPOCHS,\n",
        "    \"DLR\":DLR,\n",
        "    \"GLR\":GLR,\n",
        "    \"beta1\":beta1,\n",
        "    \"G_DROPOUT\":G_DROPOUT,\n",
        "    \"D_DROPOUT\":D_DROPOUT,\n",
        "    \"real_range\":real_range,\n",
        "    \"fake_range\":fake_range,\n",
        "    \"ngpu\":ngpu,\n",
        "    \"convert_to_grayscale\": convert_to_grayscale,\n",
        "    \"resize_images\": resize_images,\n",
        "    \"crop_images\": crop_images,\n",
        "    \"random_rotation_degrees\": random_rotation_degrees,\n",
        "    \"torch_version\": torch.__version__,\n",
        "    \"gpu_name\": gpu_name,\n",
        "    \"gpu_memory\": gpu_memory,\n",
        "    \"cuda_ver\": torch.version.cuda\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKsVXP8TYiyY"
      },
      "source": [
        "# Initialze Weights and Biases.  You'll need account.\n",
        "if RESUME_ID != \"\":\n",
        "  # config=experiment_settings,\n",
        "    wandb.init(id=RESUME_ID, project=\"deep-arcane\", resume=\"allow\")\n",
        "    if wandb.config[\"gpu_name\"] != gpu_name:\n",
        "      print(\"WOW! This is not the GPU you are looking for....\")\n",
        "      input()\n",
        "else:\n",
        "    wandb.init(config=experiment_settings, project=\"deep-arcane\")\n",
        "\n",
        "model_path = f\"/content/gdrive/MyDrive/dl_models/deep_arcane_models/{wandb.run.id}/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BhJWfIRdNmh"
      },
      "source": [
        "sample_image_path = \"/content/data/clean_bold_magic_symbols/2.png\"\n",
        "\n",
        "def add_margins(image, image_size, random_rotation_degrees, color = (255, 255, 255)):\n",
        "  \n",
        "  # Get margin size.\n",
        "  margin = image_size\n",
        "\n",
        "  # Rotation\n",
        "  rotation = random.randint(random_rotation_degrees[0], random_rotation_degrees[1])\n",
        "\n",
        "  # Create a bigger image.\n",
        "  tmp_img = Image.new(\"RGB\", \n",
        "                      (image_size + margin, image_size + margin), \n",
        "                      color = color\n",
        "  )\n",
        "\n",
        "  # Paste the old image in the center\n",
        "  cords = (\n",
        "           round((tmp_img.size[0]-image.size[0])/2),\n",
        "           round((tmp_img.size[1]-image.size[1])/2)\n",
        "  )\n",
        "  tmp_img.paste(image, cords)\n",
        "\n",
        "  # Rotate the image.\n",
        "  tmp_img = tmp_img.rotate(rotation)\n",
        "\n",
        "  # Crop the image.\n",
        "  crop_quarter_size = round(image_size / 2)\n",
        "  crop_dims = (crop_quarter_size, \n",
        "               crop_quarter_size, \n",
        "               tmp_img.size[0] - crop_quarter_size, # Width - margin.\n",
        "               tmp_img.size[1] - crop_quarter_size) # Height - margin\n",
        "  tmp_img = tmp_img.crop(crop_dims)\n",
        "\n",
        "  # Sharp\n",
        "  factor = 50\n",
        "  tmp_img = ImageEnhance.Sharpness(tmp_img).enhance(factor)\n",
        "  \n",
        "  if len(color) > 1:\n",
        "    tmp_img = tmp_img.convert(\"1\")\n",
        "\n",
        "  return tmp_img\n",
        "\n",
        "img = Image.open(sample_image_path)\n",
        "img = add_margins(img, 128, random_rotation_degrees)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "def image_loader(path):\n",
        "  image = Image.open(path)\n",
        "  image = add_margins(image, IMAGE_SIZE, random_rotation_degrees)\n",
        "  return image\n",
        "\n",
        "def save_model(path, netG, netD, optimizerG, optimizerD, EPOCHS, criterion, prefix=\"\"):\n",
        "  try:\n",
        "    os.makedirs(path)\n",
        "  except:\n",
        "    print(\"Folder exists\")\n",
        "\n",
        "  model_file_path = path + f\"{prefix}deep_arcane.model\"\n",
        "\n",
        "  # Save Model\n",
        "  torch.save(\n",
        "      {\n",
        "        \"generator\": netG.state_dict(),\n",
        "        \"discriminator\": netD.state_dict(),\n",
        "        \"generator_optimizer\": optimizerG.state_dict(),\n",
        "        \"discriminator_optimizer\": optimizerD.state_dict(),\n",
        "        \"epoch\": EPOCHS,\n",
        "        \"loss\": criterion,\n",
        "      }, model_file_path\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5SAT1OBTzBT"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztB2UOHVTyaH"
      },
      "source": [
        "\n",
        "# Normalize the images.\n",
        "if NC == 1:\n",
        "    normalize = transforms.Normalize((0.5), (0.5))\n",
        "else:\n",
        "    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "# We can use an image folder dataset the way we have it setup.\n",
        "# Create the dataset\n",
        "transforms_to_apply = [\n",
        "                       transforms.ToTensor(), \n",
        "                       normalize,\n",
        "]\n",
        "\n",
        "dataset = dset.ImageFolder(root=dataroot, \n",
        "                           loader=image_loader, \n",
        "                           transform=transforms.Compose(transforms_to_apply)\n",
        ")\n",
        "test_dataset = torch.utils.data.Subset(dataset, torch.arange(COUNT_OF_TRAINING_IMGS))\n",
        "\n",
        "print(f\"Found {len(dataset.imgs)} images in {dataroot}\")\n",
        "\n",
        "# Create the dataloader\n",
        "dataloader = idist.auto_dataloader(\n",
        "    dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    num_workers=2, \n",
        "    shuffle=True, \n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "test_dataloader = idist.auto_dataloader(\n",
        "    test_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    num_workers=2, \n",
        "    shuffle=False, \n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V_HQE5rK7Py"
      },
      "source": [
        "## Display Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPjZTMJOK9hB"
      },
      "source": [
        "def display_generated_images(tensor, samples):\n",
        "    images = []\n",
        "    samples if tensor.shape[0] > samples else tensor.shape[0]\n",
        "    for i in range(0, samples):\n",
        "        image = tensor[i].detach().cpu().reshape(128, 128, 1)\n",
        "        images.append(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(image.reshape([128, 128]), cmap=\"gray\")\n",
        "        plt.show()\n",
        "    return images\n",
        "\n",
        "def create_display_grid(images):\n",
        "    grid_size = round(len(images) / 4)\n",
        "    f, axarr = plt.subplots(grid_size, grid_size)\n",
        "    \n",
        "    index = 0\n",
        "    for row in range(0, grid_size):\n",
        "        for col in range(0, grid_size):\n",
        "            if index <= len(images):\n",
        "                axarr[row,col].imshow(images[index], cmap=\"gray\")\n",
        "                axarr[row,col].axis('off')\n",
        "                index += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "def convert_tensor_to_image(image, width, height):\n",
        "    # We multiply by 255, as the image is normalized 0-1.\n",
        "    image = Image.fromarray(image.detach().cpu().numpy().reshape([width, height]) * 255)\n",
        "    plt.imshow(image)\n",
        "    color_img = Image.new(\"RGB\", image.size)\n",
        "    color_img.paste(image)\n",
        "    return color_img\n",
        "    \n",
        "def convert_tensor_to_image(image, width, height):\n",
        "    image = Image.fromarray(image.detach().cpu().numpy().reshape([width, height]) * 255)\n",
        "    plt.imshow(image)\n",
        "    color_img = Image.new(\"RGB\", image.size)\n",
        "    color_img.paste(image)\n",
        "    return color_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2tNK3CFK_NK"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1tdpShQLA_q"
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        # nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "        \n",
        "        \n",
        "# Generator Code\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu, dropout):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.dropout = dropout\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(latent_dim, NGF * 16, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(NGF * 16),\n",
        "            nn.Dropout2d(p=dropout),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.GELU(),\n",
        "            # state size. (NGF*16) x 4 x 4\n",
        "            nn.ConvTranspose2d(NGF * 16, NGF * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(NGF * 8),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.GELU(),\n",
        "            # state size. (NGF*8) x 8 x 8\n",
        "            nn.ConvTranspose2d(NGF * 8, NGF * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(NGF * 4),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.GELU(),\n",
        "            # state size. (NGF*4) x 16 x 16 \n",
        "            nn.ConvTranspose2d(NGF * 4, NGF * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(NGF * 2),\n",
        "            nn.Dropout2d(p=dropout),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.GELU(),\n",
        "            # state size. (NGF*2) x 32 x 32\n",
        "            nn.ConvTranspose2d(NGF * 2,     NGF, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(NGF),\n",
        "            # nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.GELU(),\n",
        "            # state size. (NGF) x 64 x 64\n",
        "            nn.ConvTranspose2d(NGF, NC, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (NC) x 128 x 128\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "    \n",
        "    \n",
        "# Create the generator\n",
        "netG = Generator(ngpu, G_DROPOUT).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Load Model\n",
        "# TODO:\n",
        "\n",
        "# Print the model\n",
        "print(netG)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu, dropout):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.kernel_size = 216\n",
        "        \n",
        "        self.output_0 = 32\n",
        "        self.output_1 = 64\n",
        "        self.output_2 = 128\n",
        "        self.output_3 = 256\n",
        "        self.output_4 = 1\n",
        "\n",
        "        self.input_1 = self.output_0\n",
        "        self.input_2 = self.output_1\n",
        "        self.input_3 = self.output_2\n",
        "        self.input_4 = self.output_3\n",
        "        \n",
        "        self.stride_0 = 3\n",
        "        self.stride_1 = 3\n",
        "        self.stride_2 = 2\n",
        "        self.stride_3 = 2\n",
        "        self.stride_4 = 2\n",
        "        \n",
        "        self.padding_0 = 1\n",
        "        self.padding_1 = 1\n",
        "        self.padding_2 = 1\n",
        "        self.padding_3 = 1\n",
        "        self.padding_4 = 1\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "\n",
        "            # input is (NC) x 128 x 128\n",
        "            nn.Conv2d(NC, NDF, 4, stride=2, padding=1, bias=False), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (NDF) x 64 x 64\n",
        "            nn.Conv2d(NDF, NDF * 2, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(NDF * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (NDF*2) x 32 x 32\n",
        "            nn.Conv2d(NDF * 2, NDF * 4, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(NDF * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (NDF*4) x 16 x 16 \n",
        "            nn.Conv2d(NDF * 4, NDF * 8, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(NDF * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (NDF*8) x 8 x 8\n",
        "            nn.Conv2d(NDF * 8, NDF * 16, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(NDF * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (NDF*16) x 4 x 4\n",
        "            nn.Conv2d(NDF * 16, 1, 4, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "    \n",
        "    \n",
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu, D_DROPOUT).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5TK6w0rLEKa"
      },
      "source": [
        "# Log metrics with wandb\n",
        "wandb.watch([netG, netD])\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss(reduction=\"mean\")\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(IMAGE_SIZE, latent_dim, 1, 1, device=device)\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=DLR, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=GLR, betas=(beta1, 0.999))\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4HP-yQhlwIz"
      },
      "source": [
        "# Continue Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IRwoNmpJvuY"
      },
      "source": [
        "MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPDS1G1iQgPt"
      },
      "source": [
        "model_path_to_load = f\"{MODEL_DIR}{wandb.run.id}/deep_arcane.model\"\n",
        "model_path_to_load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmF8HcYkl0JI"
      },
      "source": [
        "if wandb.run.resumed:\n",
        "\n",
        "    checkpoint = torch.load(model_path_to_load)\n",
        "\n",
        "    netG.load_state_dict(checkpoint[\"generator\"])\n",
        "    netD.load_state_dict(checkpoint[\"discriminator\"])\n",
        "    optimizerG.load_state_dict(checkpoint[\"generator_optimizer\"])\n",
        "    optimizerD.load_state_dict(checkpoint[\"discriminator_optimizer\"])\n",
        "\n",
        "    EPOCHS += checkpoint[\"epoch\"]\n",
        "    starting_epoch = checkpoint[\"epoch\"]\n",
        "    print(\"Resumed model\")\n",
        "    del checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edPS6pVB-IuZ"
      },
      "source": [
        "# Static noise for generating images comparable outputs.\n",
        "static_noise = torch.randn(samples, latent_dim, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvyPH30RzUjI"
      },
      "source": [
        "## Training Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzk6bN6uzUNB"
      },
      "source": [
        " \n",
        " def train_step(engine, data):               \n",
        "      # Smooth labels.\n",
        "      real_label = random.uniform(real_range[0], real_range[1])\n",
        "      fake_label = random.uniform(fake_range[0], fake_range[1])\n",
        "\n",
        "      # Set the models for training\n",
        "      netG.train()\n",
        "      netD.train()\n",
        "\n",
        "      ############################\n",
        "      # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "      ###########################\n",
        "      ## Train with all-real batch\n",
        "      netD.zero_grad()\n",
        "      # Format batch\n",
        "      real = data[0].to(idist.device())\n",
        "      b_size = real.size(0)\n",
        "      label = torch.full((b_size,), real_label, dtype=torch.float, device=idist.device())\n",
        "      # Forward pass real batch through D\n",
        "      output1 = netD(real).view(-1)\n",
        "      # Calculate loss on all-real batch\n",
        "      errD_real = criterion(output1, label)\n",
        "      # Calculate gradients for D in backward pass\n",
        "      errD_real.backward()\n",
        "\n",
        "      ## Train with all-fake batch\n",
        "      # Generate batch of latent vectors\n",
        "      noise = torch.randn(b_size, latent_dim, 1, 1, device=idist.device())\n",
        "      # Generate fake image batch with G\n",
        "      fake = netG(noise)\n",
        "      label.fill_(fake_label)\n",
        "      # Classify all fake batch with D\n",
        "      output2 = netD(fake.detach()).view(-1)\n",
        "      # Calculate D's loss on the all-fake batch\n",
        "      errD_fake = criterion(output2, label)\n",
        "      # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "      errD_fake.backward()\n",
        "      # Compute error of D as sum over the fake and the real batches\n",
        "      errD = errD_real + errD_fake\n",
        "      # Update D\n",
        "      optimizerD.step()\n",
        "\n",
        "      ############################\n",
        "      # (2) Update G network: maximize log(D(G(z)))\n",
        "      ###########################\n",
        "      netG.zero_grad()\n",
        "      label.fill_(real_label)  # fake labels are real for generator cost\n",
        "      # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "      output3 = netD(fake).view(-1)\n",
        "      # Calculate G's loss based on this output\n",
        "      errG = criterion(output3, label)\n",
        "      # Calculate gradients for G\n",
        "      errG.backward()\n",
        "      # Update G\n",
        "      optimizerG.step()\n",
        "      \n",
        "      return {\n",
        "        \"Loss_G\" : errG.item(),\n",
        "        \"Loss_D\" : errD.item(),\n",
        "        \"D_x\": output1.mean().item(),\n",
        "        \"D_G_z1\": output2.mean().item(),\n",
        "        \"D_G_z2\": output3.mean().item(),\n",
        "      }\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFKgAa1iSp_J"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyIYSMXR0egl"
      },
      "source": [
        "trainer = Engine(train_step)\n",
        "\n",
        "# If continuining a training session, load state:\n",
        "if wandb.run.resumed:\n",
        "    trainer.load_state_dict({\"epoch\": starting_epoch, \"max_epochs\": EPOCHS, \"epoch_length\": COUNT_OF_TRAINING_IMGS, \"rng_state\": None})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsLrvfHs08I-"
      },
      "source": [
        "# def initialize_fn(m):\n",
        "#     classname = m.__class__.__name__\n",
        "#     if classname.find('Conv') != -1:\n",
        "#         nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "#     elif classname.find('BatchNorm') != -1:\n",
        "#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "#         nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# @trainer.on(Events.STARTED)\n",
        "# def init_weights():\n",
        "#     netD.apply(initialize_fn)\n",
        "#     netG.apply(initialize_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2d7NW2G1MQL"
      },
      "source": [
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def store_losses(engine):\n",
        "    o = engine.state.output\n",
        "    G_losses.append(o[\"Loss_G\"])\n",
        "    D_losses.append(o[\"Loss_D\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSar9j0w1PmI"
      },
      "source": [
        "img_list = []\n",
        "\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=500))\n",
        "def store_images(engine):\n",
        "    with torch.no_grad():\n",
        "        fake = netG(fixed_noise).cpu()\n",
        "    img_list.append(fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7exkFwqK-UML"
      },
      "source": [
        "## Log Images\n",
        "Using a static distribution of noise, log the images across the training session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwyQz82K91VH"
      },
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_images():\n",
        "      # Display samples \n",
        "      netG.eval()\n",
        "      generated_images = netG(static_noise)\n",
        "      netG.train()\n",
        "      images = display_generated_images(generated_images, samples)\n",
        "      pil_images = [convert_tensor_to_image(image, IMAGE_SIZE, IMAGE_SIZE) for image in images]   \n",
        "      wandb.log({\"example\": [wandb.Image(img) for img in pil_images]})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD9YUs8e1Sr0"
      },
      "source": [
        "from ignite.metrics import FID, InceptionScore\n",
        "fid_metric = FID(device=idist.device())\n",
        "is_metric = InceptionScore(device=idist.device(), output_transform=lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JyH79SA1cqO"
      },
      "source": [
        "import PIL.Image as Image\n",
        "\n",
        "def interpolate(batch):\n",
        "    arr = []\n",
        "    for img in batch:\n",
        "        pil_img = transforms.ToPILImage()(img)\n",
        "        # If black and white, ensure it is converted to 3-channel for comparing\n",
        "        # to Inception images.\n",
        "        pil_img = pil_img.convert('RGB')\n",
        "        # If the image is not 299x299, resize it to be comparable.\n",
        "        resized_img = pil_img.resize((299,299), Image.BILINEAR)\n",
        "        arr.append(transforms.ToTensor()(resized_img))\n",
        "    return torch.stack(arr)\n",
        "\n",
        "\n",
        "def evaluation_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(BATCH_SIZE, latent_dim, 1, 1, device=idist.device())\n",
        "        netG.eval()\n",
        "        fake_batch = netG(noise)\n",
        "        fake = interpolate(fake_batch)\n",
        "        real = interpolate(batch[0])\n",
        "        return fake, real"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KI2yw3I1fnQ"
      },
      "source": [
        "evaluator = Engine(evaluation_step)\n",
        "fid_metric.attach(evaluator, \"fid\")\n",
        "is_metric.attach(evaluator, \"is\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NWlhSX11iOk"
      },
      "source": [
        "\n",
        "fid_values = []\n",
        "is_values = []\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED(every=(EPOCH_TO_EVAL)))\n",
        "def log_training_results(engine):\n",
        "\n",
        "    # Get current epoch.\n",
        "    epoch = engine.state.epoch\n",
        "\n",
        "    # Evaluate model.\n",
        "    evaluator.run(test_dataloader, max_epochs=1)\n",
        "    metrics = evaluator.state.metrics\n",
        "    fid_score = metrics['fid']\n",
        "    is_score = metrics['is']\n",
        "    fid_values.append(fid_score)\n",
        "    is_values.append(is_score)\n",
        "\n",
        "    # Grab the NN losses.\n",
        "    loss_g = engine.state.output[\"Loss_G\"]\n",
        "    loss_d = engine.state.output[\"Loss_D\"]\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{EPOCHS}] Metric Scores\")\n",
        "    print(f\"*    FID : {fid_score:4f}\")\n",
        "    print(f\"*     IS : {is_score:4f}\")\n",
        "    print(f\"* Loss_G : {loss_g:4f}\")\n",
        "    print(f\"* Loss_D : {loss_d:4f}\")\n",
        "\n",
        "    # Log to Weights and Biases\n",
        "    wandb.log({\"epoch\": epoch, \n",
        "               \"FID\": fid_score, \n",
        "               \"IS\": is_score,\n",
        "               \"Loss_G\": loss_g, \n",
        "               \"Loss_D\": loss_d})\n",
        "    \n",
        "    # Handle saving model if lowest FID score.\n",
        "    if epoch > EPOCH_TO_START_SAVING and fid_score > min(fid_values):\n",
        "        print(\"Saving model: Started\")\n",
        "\n",
        "        # To prevent curruption, we save a temporary model, and then move it in place\n",
        "        # once we are assured it has completely saved.  This gets around sessions\n",
        "        # dying during a model save.\n",
        "        save_model(model_path, netG, netD, optimizerG, optimizerD, epoch, criterion, prefix=\"tmp_\")\n",
        "\n",
        "        # Seems like the code continues to execute before results are secure\n",
        "        # in the Google drive. Let's wait a bit before trying to move it.\n",
        "        sleep(15)\n",
        "\n",
        "        # Save a \"tmp\" model, in case this model is interrupted during saving.\n",
        "        if os.path.exists(f\"{MODEL_DIR}{wandb.run.id}/tmp_deep_arcane.model\"):\n",
        "        \n",
        "            # Since we're here, we assume the model saved correctly and can make \n",
        "            # it the recorded model.\n",
        "            move_command = f\"mv {MODEL_DIR}{wandb.run.id}/tmp_deep_arcane.model {MODEL_DIR}{wandb.run.id}/deep_arcane.model\"\n",
        "            os.system(move_command)\n",
        "\n",
        "            if gauth.access_token_expired:\n",
        "                gauth.Refresh()\n",
        "\n",
        "            # After moving the files, we need to empty the trash to keep the \n",
        "            # GDrive from filling up.\n",
        "            [print(f\"Deleted: {gfile.Delete()}\") for gfile in pdrive.ListFile({'q': \"trashed = True\"}).GetList()]\n",
        "\n",
        "            print(\"Saving model: Complete\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6QA2Uv01lWJ"
      },
      "source": [
        "from ignite.metrics import RunningAverage\n",
        "\n",
        "\n",
        "RunningAverage(output_transform=lambda x: x[\"Loss_G\"]).attach(trainer, 'Loss_G')\n",
        "RunningAverage(output_transform=lambda x: x[\"Loss_D\"]).attach(trainer, 'Loss_D')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHBbHlzc1oEi"
      },
      "source": [
        "from ignite.contrib.handlers import ProgressBar\n",
        "\n",
        "\n",
        "ProgressBar().attach(trainer, metric_names=['Loss_G','Loss_D'])\n",
        "ProgressBar().attach(evaluator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRLgFB1k1pGz"
      },
      "source": [
        "def training(*args):\n",
        "    trainer.run(dataloader, max_epochs=EPOCHS)\n",
        "\n",
        "with idist.Parallel(backend='nccl') as parallel:\n",
        "    parallel.run(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2RUDY2Qkqb_"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNzu5A5xjxwe"
      },
      "source": [
        "# save_model(model_path, netG, netD, optimizerG, optimizerD, EPOCHS, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1QLxrlWnr5"
      },
      "source": [
        "## Ignite\n",
        "https://pytorch-ignite.ai/blog/gan-evaluation-with-fid-and-is/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrsHjvx2NE5X"
      },
      "source": [
        "# TODO:\n",
        "# 1. Modify lr per generator and discriminator\n",
        "# 2. Update image plotter to be neater.  I.e., image grid.\n",
        "# 3. Use \n",
        "#       pip install pipreqs\n",
        "#       pipreqs /path/to/project\n",
        "#    To preserve the requirements.txt as a WandB object.\n",
        "# 4. Modify sampler to use static input.\n",
        "# 5. Pre-train with SVGs\n",
        "# 6. Create data augumentation schedule.  I.e., for the first half of the training\n",
        "#.   making augmentation heavy, and taper off closer to finalization.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B0ieplqXwvI"
      },
      "source": [
        "## Good GAN Reads\n",
        "https://towardsdatascience.com/why-do-gans-need-so-much-noise-1eae6c0fb177\n",
        "\n",
        "## Great Article on Activation\n",
        "https://himanshuxd.medium.com/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e\n",
        "\n",
        "## Adding FID\n",
        "https://colab.research.google.com/github/pytorch-ignite/pytorch-ignite.ai/blob/gh-pages/blog/2021-08-11-GAN-evaluation-using-FID-and-IS.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5gf0evojQn1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocsZXFMaPqqV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}